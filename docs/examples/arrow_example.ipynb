{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrow example\n",
    "\n",
    "This example illustrates how to convert Arrow data that contains power-grid-model data to NumPy structured arrays, which the power-grid-model requests.\n",
    "\n",
    "It is by no means intended to provide complete documentation on the topic, but only to show how such conversions could be done.\n",
    "\n",
    "This example uses `pyarrow.RecordBatch` to demonstrate zero copy operations. The user can choose a `pyarrow.Table` or other structures based on the requirement.\n",
    "\n",
    "**NOTE:** To run this example, the optional `examples` dependencies are required:\n",
    "\n",
    "```sh\n",
    "pip install .[examples]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from IPython.display import display\n",
    "from typing import Iterable\n",
    "\n",
    "from power_grid_model import (\n",
    "    PowerGridModel,\n",
    "    initialize_array,\n",
    "    CalculationMethod,\n",
    "    power_grid_meta_data,\n",
    "    ComponentType,\n",
    "    DatasetType,\n",
    "    ComponentAttributeFilterOptions,\n",
    ")\n",
    "from power_grid_model.data_types import SingleColumnarData\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A constant showing error message\n",
    "ZERO_COPY_ERROR_MSG = \"Zero-copy conversion requested, but the data types do not match.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model\n",
    "\n",
    "For clarity, a simple network is created. More complex cases work similarly and can be found in the other examples:\n",
    "\n",
    "```\n",
    "node 1 ---- line 4 ---- node 2 ----line 5 ---- node 3\n",
    "   |                       |                      |\n",
    "source 6               sym_load 7             sym_load 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single symmetric calculations\n",
    "\n",
    "Construct the input data for the model and construct the actual model.\n",
    "\n",
    "Arrow uses a columnar data format while the power-grid-model offers both: row based or columnar data format.\n",
    "Because of this, the columnar data format of power-grid-model provides a zero-copy interface for Arrow data. This differs from the row-based data format, for which conversions always require a copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the power-grid-model data types\n",
    "\n",
    "See which attributes exist for a given component and which data types are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_input_dtype = initialize_array(\"input\", \"node\", 0).dtype\n",
    "line_input_dtype = initialize_array(\"input\", \"line\", 0).dtype\n",
    "source_input_dtype = initialize_array(\"input\", \"source\", 0).dtype\n",
    "asym_load_input_dtype = initialize_array(\"input\", \"asym_load\", 0).dtype\n",
    "print(\"node:\", node_input_dtype)\n",
    "print(\"line:\", line_input_dtype)\n",
    "print(\"source:\", source_input_dtype)\n",
    "print(\"asym_load:\", asym_load_input_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primitive types of each attribute in the arrow tables need to match to make the operation efficient.\n",
    "A zero copy is not guaranteed if the data types from power_grid_meta_data / initialize_array are not used.\n",
    "Note that the asymmetric type of attribute in power-grid-model has a shape of `(3,)` along with a specific type. These represent the 3 phases of electrical system.\n",
    "Hence asymmetric attributes need to be handled specially. \n",
    "\n",
    "In this tutorial we use the respective primitive types for the symmetrical attributes and a `FixedSizeListArray` of the primitive types with length 3 for asymmetrical attributes. This results in them being stored as contigious memory which would enable zero copy conversion. There might be other ways to approach this problem too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Schema\n",
    "\n",
    "We can make the task of assigning types easier by creating a schema based on the `DatasetType` and `ComponentType` directly from `power_grid_meta_data`. \n",
    "They can then directly be used to construct the `RecordBatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgm_schema(dataset_type: DatasetType, component_type: ComponentType, attributes: Iterable[str] | None = None):\n",
    "    schemas = []\n",
    "    component_dtype = power_grid_meta_data[dataset_type][component_type].dtype\n",
    "    for meta_attribute, (dtype, _) in component_dtype.fields.items():\n",
    "        if attributes is not None and meta_attribute not in attributes:\n",
    "            continue\n",
    "        if dtype.shape == (3,):\n",
    "            pa_dtype = pa.list_(pa.from_numpy_dtype(dtype.base), 3)\n",
    "        else:\n",
    "            pa_dtype = pa.from_numpy_dtype(dtype)\n",
    "        schemas.append((meta_attribute, pa_dtype))\n",
    "    return pa.schema(schemas)\n",
    "\n",
    "\n",
    "print(\"-------node combined asym scehma-------\")\n",
    "print(pgm_schema(DatasetType.input, ComponentType.node))\n",
    "print(\"-------asym load combined asym scehma-------\")\n",
    "print(pgm_schema(DatasetType.input, ComponentType.asym_load))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the grid using Arrow tables\n",
    "\n",
    "The [power-grid-model documentation on Components](https://power-grid-model.readthedocs.io/en/stable/user_manual/components.html) provides documentation on which components are required and which ones are optional.\n",
    "\n",
    "Construct the Arrow data as a table with the correct headers and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dict = {\"id\": [1, 2, 3], \"u_rated\": [10500.0, 10500.0, 10500.0]}\n",
    "\n",
    "\n",
    "lines_dict = {\n",
    "    \"id\": [4, 5],\n",
    "    \"from_node\": [1, 2],\n",
    "    \"to_node\": [2, 3],\n",
    "    \"from_status\": [1, 1],\n",
    "    \"to_status\": [1, 1],\n",
    "    \"r1\": [0.11, 0.15],\n",
    "    \"x1\": [0.12, 0.16],\n",
    "    \"c1\": [4.1e-05, 5.4e-05],\n",
    "    \"tan1\": [0.1, 0.1],\n",
    "    \"r0\": [0.01, 0.05],\n",
    "    \"x0\": [0.22, 0.06],\n",
    "    \"c0\": [4.1e-05, 5.4e-05],\n",
    "    \"tan0\": [0.4, 0.1],\n",
    "}\n",
    "\n",
    "sources_dict = {\"id\": [6], \"node\": [1], \"status\": [1], \"u_ref\": [1.0]}\n",
    "\n",
    "sym_loads_dict = {\n",
    "    \"id\": [7, 8],\n",
    "    \"node\": [2, 3],\n",
    "    \"status\": [1, 1],\n",
    "    \"type\": [0, 0],\n",
    "    \"p_specified\": [1.0, 2.0],\n",
    "    \"q_specified\": [0.5, 1.5],\n",
    "}\n",
    "\n",
    "nodes = pa.record_batch(nodes_dict, schema=pgm_schema(DatasetType.input, ComponentType.node, nodes_dict.keys()))\n",
    "lines = pa.record_batch(lines_dict, schema=pgm_schema(DatasetType.input, ComponentType.line, lines_dict.keys()))\n",
    "sources = pa.record_batch(sources_dict, schema=pgm_schema(DatasetType.input, ComponentType.source, sources_dict.keys()))\n",
    "sym_loads = pa.record_batch(\n",
    "    sym_loads_dict, schema=pgm_schema(DatasetType.input, ComponentType.sym_load, sym_loads_dict.keys())\n",
    ")\n",
    "\n",
    "nodes\n",
    "# the record batches of the other components can be printed similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Arrow data to power-grid-model input data\n",
    "\n",
    "The Arrow record batch or tables can then be converted to row based data or columnar data.\n",
    "Converting Arrow data to columnar NumPy arrays is recommended to leverage the columnar nature of Arrow data. \n",
    "This conversion can be done with zero-copy operations.\n",
    "\n",
    "Similar approach be adopted by the user to convert to row based data.\n",
    "\n",
    "```{note}\n",
    "The option of `zero_copy_only` in the function below is added in this demo to verify no copies are made. Its usage is not mandatory to do zero copy conversion.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow_to_numpy(\n",
    "    data: pa.RecordBatch, dataset_type: DatasetType, component_type: ComponentType, zero_copy_only: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Convert Arrow data to NumPy data.\"\"\"\n",
    "    result = {}\n",
    "    result_dtype = power_grid_meta_data[dataset_type][component_type].dtype\n",
    "    for name, column in zip(data.column_names, data.columns):\n",
    "        column_data = column.to_numpy(zero_copy_only=zero_copy_only)\n",
    "        if zero_copy_only and column_data.dtype != result_dtype[name]:\n",
    "            raise ValueError(ZERO_COPY_ERROR_MSG)\n",
    "        result[name] = column_data.astype(dtype=result_dtype[name], copy=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "node_input = arrow_to_numpy(nodes, DatasetType.input, ComponentType.node, zero_copy_only=True)\n",
    "line_input = arrow_to_numpy(lines, DatasetType.input, ComponentType.line)\n",
    "source_input = arrow_to_numpy(sources, DatasetType.input, ComponentType.source)\n",
    "sym_load_input = arrow_to_numpy(sym_loads, DatasetType.input, ComponentType.sym_load)\n",
    "\n",
    "node_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the complete input data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    ComponentType.node: node_input,\n",
    "    ComponentType.line: line_input,\n",
    "    ComponentType.source: source_input,\n",
    "    ComponentType.sym_load: sym_load_input,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: validate the input data\n",
    "from power_grid_model.validation import validate_input_data\n",
    "\n",
    "validate_input_data(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the power-grid-model\n",
    "\n",
    "The `output_component_types` argument is set to `ComponentAttributeFilterOptions.relevant` to given out columnar data.\n",
    "\n",
    "For more extensive examples, visit the [power-grid-model documentation](https://power-grid-model.readthedocs.io/en/stable/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the model\n",
    "model = PowerGridModel(input_data=input_data, system_frequency=50)\n",
    "\n",
    "# run the calculation\n",
    "sym_result = model.calculate_power_flow(output_component_types=ComponentAttributeFilterOptions.relevant)\n",
    "\n",
    "# use pandas to tabulate and display the results\n",
    "sym_node_result = sym_result[ComponentType.node]\n",
    "display(pd.DataFrame(sym_node_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the symmetric result to Arrow format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting symmetrical results is straightforward by using schema from [Creating Schema](#creating-a-schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_sym_node_result = pa.record_batch(\n",
    "    sym_node_result, schema=pgm_schema(DatasetType.sym_output, ComponentType.node, sym_node_result.keys())\n",
    ")\n",
    "pa_sym_node_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single asymmetric calculations\n",
    "\n",
    "Asymmetric calculations have a tuple of values for some of the attributes and are not easily convertible to record batches.\n",
    "Instead, one can have a look at the individual components of those attributes and/or flatten the arrays to access all components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymmetric input\n",
    "\n",
    "To illustrate the conversion, let's consider a similar grid but with asymmetric loads.\n",
    "\n",
    "```\n",
    "node 1 ---- line 4 ---- node 2 ----line 5 ---- node 3\n",
    "   |                       |                      |\n",
    "source 6              asym_load 7            asym_load 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_loads_dict = {\n",
    "    \"id\": [7, 8],\n",
    "    \"node\": [2, 3],\n",
    "    \"status\": [1, 1],\n",
    "    \"type\": [0, 0],\n",
    "    \"p_specified\": [[1.0, 1.0e-2, 1.1e-2], [2.0, 2.5, 4.5e2]],\n",
    "    \"q_specified\": [[0.5, 1.5e3, 0.1], [1.5, 2.5, 1.5e3]],\n",
    "}\n",
    "\n",
    "asym_loads = pa.record_batch(\n",
    "    asym_loads_dict, schema=pgm_schema(DatasetType.input, ComponentType.asym_load, asym_loads_dict.keys())\n",
    ")\n",
    "\n",
    "asym_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow_to_numpy_asym(\n",
    "    data: pa.RecordBatch, dataset_type: DatasetType, component_type: ComponentType, zero_copy_only: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Convert asymmetric Arrow data to NumPy data.\n",
    "\n",
    "    This function is similar to the arrow_to_numpy function, but also supports asymmetric data.\"\"\"\n",
    "    result = {}\n",
    "    result_dtype = power_grid_meta_data[dataset_type][component_type].dtype\n",
    "\n",
    "    for name in result_dtype.names:\n",
    "        if name not in data.column_names:\n",
    "            continue\n",
    "        dtype = result_dtype[name]\n",
    "\n",
    "        if len(dtype.shape) == 0:\n",
    "            column_data = data.column(name).to_numpy(zero_copy_only=zero_copy_only)\n",
    "        else:\n",
    "            column_data = data.column(name).flatten().to_numpy(zero_copy_only=zero_copy_only).reshape(-1, 3)\n",
    "\n",
    "        if zero_copy_only and column_data.dtype.base != dtype.base:\n",
    "            raise ValueError(ZERO_COPY_ERROR_MSG)\n",
    "        result[name] = column_data.astype(dtype=dtype.base, copy=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "asym_load_input = arrow_to_numpy_asym(asym_loads, DatasetType.input, ComponentType.asym_load, zero_copy_only=True)\n",
    "\n",
    "asym_load_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the power-grid-model in asymmetric calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_input_data = {\n",
    "    ComponentType.node: node_input,\n",
    "    ComponentType.line: line_input,\n",
    "    ComponentType.source: source_input,\n",
    "    ComponentType.asym_load: asym_load_input,\n",
    "}\n",
    "\n",
    "validate_input_data(asym_input_data, symmetric=False)\n",
    "\n",
    "# construct the model\n",
    "asym_model = PowerGridModel(input_data=asym_input_data, system_frequency=50)\n",
    "\n",
    "# run the calculation\n",
    "asym_result = asym_model.calculate_power_flow(\n",
    "    symmetric=False, output_component_types=ComponentAttributeFilterOptions.relevant\n",
    ")\n",
    "\n",
    "# use pandas to display the results, but beware the data types\n",
    "pd.DataFrame(asym_result[ComponentType.node][\"u_angle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert asymmetric power-grid-model output data to Arrow output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_columnar_to_arrow(\n",
    "    data: SingleColumnarData, dataset_type: DatasetType, component_type: ComponentType\n",
    ") -> pa.RecordBatch:\n",
    "    \"\"\"Convert NumPy data to Arrow data.\"\"\"\n",
    "    # pa.record_batch.from_arrays(data, schema=pgm_schema(DatasetType.result, ComponentType.node))\n",
    "    component_pgm_schema = pgm_schema(dataset_type, component_type, data.keys())\n",
    "    pa_columns = {}\n",
    "    for attribute, data in data.items():\n",
    "        primitive_type = component_pgm_schema.field(attribute).type\n",
    "\n",
    "        if data.ndim == 2 and data.shape[1] == 3:\n",
    "            pa_columns[attribute] = pa.FixedSizeListArray.from_arrays(data.flatten(), type=primitive_type)\n",
    "        else:\n",
    "            pa_columns[attribute] = pa.array(data, type=primitive_type)\n",
    "    return pa.record_batch(pa_columns, component_pgm_schema)\n",
    "\n",
    "\n",
    "pa_asym_node_result = numpy_columnar_to_arrow(\n",
    "    asym_result[ComponentType.node], DatasetType.asym_output, ComponentType.node\n",
    ")\n",
    "\n",
    "pa_asym_node_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch data\n",
    "\n",
    "power-grid-model supports batch calculations by providing an `update_data` argument, as shown in [this example](https://power-grid-model.readthedocs.io/en/stable/examples/Power%20Flow%20Example.html#batch-calculation).\n",
    "\n",
    "Both the `update_data` and the output result are similar to the `input_data` and output data in the above, except that they have another dimension representing the batch index: the first index in the NumPy structured arrays.\n",
    "\n",
    "This extra index can be represented in Arrow using a [`RecordBatch`](https://arrow.apache.org/docs/cpp/api/table.html#two-dimensional-datasets) or using any other multi-index data format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
